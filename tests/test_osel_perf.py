#!/usr/bin/env python3
"""
Test script for osel performance optimization.

This script tests the osel command performance before and after optimization.
The optimization should apply the ocls batching pattern to method enumeration:
- Current: ~2N expression calls for N methods
- Target: Batch method_getName() + sel_getName() into consolidated buffers
- Add per-class method caching

Uses a shared LLDB session for faster test execution.

Expected improvements:
- Reduced expression evaluation count (from 2N to ~N/batch_size)
- Similar or better execution time
- Optional: method caching for instant subsequent queries

Test classes with varying method counts:
- NSObject: Small (~10-20 methods)
- NSString: Medium (~100 methods)
- UIViewController: Large (~300+ methods)
- IDSService: Private framework class
"""

import sys
import re
import time
from test_helpers import (
    TestResult, check_hello_world_binary, run_shared_test_suite, SharedLLDBSession
)


# =============================================================================
# Validator Functions
# =============================================================================

def validate_basic_functionality():
    """Validator for basic osel functionality."""
    def validator(output):
        if 'Instance methods' in output and 'Class methods' in output:
            total_match = re.search(r'Total: (\d+)', output)
            if total_match:
                count = int(total_match.group(1))
                if count > 0:
                    return True, f"Found {count} methods"
                return False, "No methods found"
            return True, "Found methods"
        return False, f"Expected method listing: {output[:300]}"
    return validator


def validate_pattern_matching():
    """Validator for pattern matching."""
    def validator(output):
        if 'init' in output.lower():
            init_count = output.lower().count('init')
            return True, f"Pattern matching works, found ~{init_count} init methods"
        return False, f"Pattern matching may be broken: {output[:300]}"
    return validator


def validate_performance_small():
    """Validator for small class performance."""
    def validator(output):
        if 'Instance methods' in output or 'Class methods' in output:
            return True, "Small class enumerated"
        return False, f"Failed: {output[:300]}"
    return validator


def validate_performance_medium():
    """Validator for medium class performance."""
    def validator(output):
        if 'Instance methods' in output or 'Class methods' in output:
            total_match = re.search(r'Total: (\d+)', output)
            if total_match:
                count = int(total_match.group(1))
                return True, f"Medium class: {count} methods"
            return True, "Medium class enumerated"
        return False, f"Failed: {output[:300]}"
    return validator


def validate_performance_large():
    """Validator for large class performance."""
    def validator(output):
        # UIViewController may not be available in command-line binaries
        if 'not found' in output.lower():
            return True, "UIViewController not available (skipped - UIKit not loaded)"
        if 'Instance methods' in output or 'Class methods' in output:
            total_match = re.search(r'Total: (\d+)', output)
            if total_match:
                count = int(total_match.group(1))
                return True, f"Large class: {count} methods"
            return True, "Large class enumerated"
        return False, f"Failed: {output[:300]}"
    return validator


def validate_private_class():
    """Validator for private class performance."""
    def validator(output):
        if 'Instance methods' in output or 'Class methods' in output:
            return True, "Private class enumerated"
        elif 'not found' in output.lower():
            return False, "IDSService not found (framework not loaded)"
        return False, f"Unexpected output: {output[:300]}"
    return validator


def validate_caching_first():
    """Validator for first run (cache population)."""
    def validator(output):
        if 'Instance methods' in output:
            return True, "First run completed"
        return False, "First run failed"
    return validator


def validate_caching_second():
    """Validator for second run (cache hit)."""
    def validator(output):
        # Both runs should complete; if caching works, second should be faster
        # We just verify both complete successfully
        if output.count('Instance methods') >= 2:
            return True, "Both runs completed (caching may speed up second)"
        elif 'Instance methods' in output:
            return True, "Command works (caching behavior not verified)"
        return False, f"Unexpected output: {output[:300]}"
    return validator


def validate_verbose_timing():
    """Validator for verbose timing output."""
    def validator(output):
        has_expr_count = 'expression' in output.lower()
        has_mem_count = 'memory' in output.lower() or 'read' in output.lower()
        has_timing = re.search(r'\d+\.\d+s', output) is not None

        if has_expr_count or has_mem_count or has_timing:
            return True, "Performance metrics shown in output"
        elif 'Instance methods' in output:
            return True, "Works but verbose metrics not implemented yet"
        return False, f"Unexpected output: {output[:300]}"
    return validator


def validate_expression_reduction():
    """Validator for expression count reduction."""
    def validator(output):
        expr_match = re.search(r'(\d+)\s*expressions?', output, re.IGNORECASE)
        method_match = re.search(r'Total: (\d+) method', output)

        if expr_match and method_match:
            expr_count = int(expr_match.group(1))
            method_count = int(method_match.group(1))
            ratio = expr_count / (2 * method_count) if method_count > 0 else 1

            if ratio < 0.5:
                return True, f"Expression count reduced: {expr_count} for {method_count} methods (ratio: {ratio:.2f})"
            return False, f"Expression count not reduced: {expr_count} for {method_count} methods"
        elif 'Instance methods' in output:
            return True, "Command works (expression count metrics not available)"
        return False, "Could not verify expression count"
    return validator


# =============================================================================
# Test Specifications
# =============================================================================

def get_test_specs():
    """Return list of test specifications."""
    return [
        # Functionality tests
        (
            "Basic functionality preserved",
            ['osel NSString'],
            validate_basic_functionality()
        ),
        (
            "Pattern matching preserved",
            ['osel NSString *init*'],
            validate_pattern_matching()
        ),
        # Performance by class size
        (
            "Performance: NSObject (small)",
            ['osel NSObject'],
            validate_performance_small()
        ),
        (
            "Performance: NSString (medium)",
            ['osel NSString'],
            validate_performance_medium()
        ),
        (
            "Performance: UIViewController (large)",
            ['osel UIViewController'],
            validate_performance_large()
        ),
        (
            "Performance: IDSService (private)",
            ['osel IDSService'],
            validate_private_class()
        ),
        # Caching tests
        (
            "Caching: First run",
            ['osel NSString'],
            validate_caching_first()
        ),
        (
            "Caching: Second run (if implemented)",
            ['osel NSString', 'osel NSString'],
            validate_caching_second()
        ),
        # Verbose/metrics tests
        (
            "Verbose timing metrics",
            ['osel --verbose NSString'],
            validate_verbose_timing()
        ),
        (
            "Expression count reduction",
            ['osel --verbose NSString'],
            validate_expression_reduction()
        ),
    ]


def main():
    """Run all osel performance tests using shared LLDB session."""

    categories = {
        "Functionality": (0, 2),
        "Performance by class size": (2, 6),
        "Caching": (6, 8),
        "Verbose/metrics": (8, 10),
    }

    passed, total = run_shared_test_suite(
        "OSEL PERFORMANCE OPTIMIZATION TEST SUITE",
        get_test_specs(),
        scripts=['scripts/objc_sel.py'],
        show_category_summary=categories
    )

    # Performance summary
    print("\n" + "-" * 70)
    print("PERFORMANCE SUMMARY")
    print("-" * 70)
    print("Note: Execution times shown in test results above.")
    print("With shared LLDB session, individual test times are more accurate.")

    sys.exit(0 if passed == total else 1)


if __name__ == '__main__':
    main()
